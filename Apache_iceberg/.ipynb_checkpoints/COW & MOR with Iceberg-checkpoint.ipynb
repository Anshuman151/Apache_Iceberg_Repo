{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca7d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05eaa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "  \t\t#packages\n",
    "        .set('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.4_2.12:1.3.1,software.amazon.awssdk:bundle:2.17.178,software.amazon.awssdk:url-connection-client:2.17.178')\n",
    "  \t\t#SQL Extensions\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\n",
    "  \t\t#Configuring Catalog\n",
    "        .set('spark.sql.catalog.spark_catalog','org.apache.iceberg.spark.SparkSessionCatalog')\n",
    "        .set('spark.sql.catalog.spark_catalog.type','hive')\n",
    "        .set('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.iceberg.type', 'hadoop')\n",
    "        .set('spark.sql.catalog.iceberg.warehouse', 'iceberg-warehouse')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5d901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/anshumanr/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/anshumanr/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.4_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-65a329a4-0ce6-4b53-bf69-ee3ba8c59d4a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.17.178 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#utils;2.17.178 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.17.178 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.17.178 in central\n",
      ":: resolution report :: resolve 882ms :: artifacts dl 67ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from local-m2-cache in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-65a329a4-0ce6-4b53-bf69-ee3ba8c59d4a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 10 already retrieved (0kB/17ms)\n",
      "23/08/16 23:26:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n"
     ]
    }
   ],
   "source": [
    "## Start Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark Running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd23ae",
   "metadata": {},
   "source": [
    "# Copy On Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4a6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43m CREATE TABLE iceberg.db.students (\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m    id int,\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    first_name string,\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    last_name string,\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    major string,\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    class_year int\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m) USING iceberg \u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m TBLPROPERTIES (\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite.delete.mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopy-on-write\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite.update.mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopy-on-write\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite.merge.mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopy-on-write\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43mPARTITIONED BY (class_year) ;\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spark.sql(''' CREATE TABLE iceberg.db.students (\n",
    "    id int,\n",
    "    first_name string,\n",
    "    last_name string,\n",
    "    major string,\n",
    "    class_year int\n",
    ") USING iceberg \n",
    " TBLPROPERTIES (\n",
    "    'write.delete.mode'='copy-on-write',\n",
    "    'write.update.mode'='copy-on-write',\n",
    "    'write.merge.mode'='copy-on-write'\n",
    ")\n",
    "PARTITIONED BY (class_year) ;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ec5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "INSERT INTO iceberg.db.students (id, first_name, last_name, major, class_year)\n",
    "VALUES\n",
    "(1, 'John', 'Doe', 'Computer Science', 2023),\n",
    "(2, 'Jane', 'Doe', 'Business', 2019),\n",
    "(3, 'Peter', 'Smith', 'Engineering', 2021),\n",
    "(4, 'Susan', 'Williams', 'Nursing', 2023),\n",
    "(5, 'David', 'Johnson', 'Law', 2020),\n",
    "(6, 'Elizabeth', 'Brown', 'Art', 2021),\n",
    "(7, 'Michael', 'Green', 'History', 2019),\n",
    "(8, 'Sarah', 'White', 'English', 2020),\n",
    "(9, 'William', 'Black', 'Mathematics', 2021),\n",
    "(10, 'Mary', 'Brown', 'Physics', 2022),\n",
    "(11, 'Thomas', 'Green', 'Chemistry', 2022),\n",
    "(12, 'Jennifer', 'White', 'Biology', 2020),\n",
    "(13, 'Charles', 'Black', 'Geology', 2020),\n",
    "(14, 'Lisa', 'Brown', 'Astronomy', 2019),\n",
    "(15, 'Henry', 'Green', 'Meteorology', 2020),\n",
    "(16, 'Nancy', 'White', 'Economics', 2022),\n",
    "(17, 'Daniel', 'Black', 'Political Science', 2022),\n",
    "(18, 'Emily', 'Brown', 'Philosophy', 2021),\n",
    "(19, 'Matthew', 'Green', 'Psychology', 2019),\n",
    "(20, 'Jessica', 'White', 'Sociology', 2021); ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64111f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----------------+----------+\n",
      "| id|first_name|last_name|            major|class_year|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "|  2|      Jane|      Doe|         Business|      2019|\n",
      "|  7|   Michael|    Green|          History|      2019|\n",
      "| 14|      Lisa|    Brown|        Astronomy|      2019|\n",
      "| 19|   Matthew|    Green|       Psychology|      2019|\n",
      "|  5|     David|  Johnson|              Law|      2020|\n",
      "|  8|     Sarah|    White|          English|      2020|\n",
      "| 12|  Jennifer|    White|          Biology|      2020|\n",
      "| 13|   Charles|    Black|          Geology|      2020|\n",
      "| 15|     Henry|    Green|      Meteorology|      2020|\n",
      "|  3|     Peter|    Smith|      Engineering|      2021|\n",
      "|  6| Elizabeth|    Brown|              Art|      2021|\n",
      "|  9|   William|    Black|      Mathematics|      2021|\n",
      "| 18|     Emily|    Brown|       Philosophy|      2021|\n",
      "| 20|   Jessica|    White|        Sociology|      2021|\n",
      "| 10|      Mary|    Brown|          Physics|      2022|\n",
      "| 11|    Thomas|    Green|        Chemistry|      2022|\n",
      "| 16|     Nancy|    White|        Economics|      2022|\n",
      "| 17|    Daniel|    Black|Political Science|      2022|\n",
      "|  1|      John|      Doe| Computer Science|      2023|\n",
      "|  4|     Susan| Williams|          Nursing|      2023|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading \n",
    "spark.sql(\"select * from iceberg.db.students\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800c7b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating\n",
    "spark.sql(\"update iceberg.db.students set major = 'zoology' where id = 4;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90b4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----------------+----------+\n",
      "| id|first_name|last_name|            major|class_year|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "|  2|      Jane|      Doe|         Business|      2019|\n",
      "|  7|   Michael|    Green|          History|      2019|\n",
      "| 14|      Lisa|    Brown|        Astronomy|      2019|\n",
      "| 19|   Matthew|    Green|       Psychology|      2019|\n",
      "|  1|      John|      Doe| Computer Science|      2023|\n",
      "|  4|     Susan| Williams|          zoology|      2023|\n",
      "|  5|     David|  Johnson|              Law|      2020|\n",
      "|  8|     Sarah|    White|          English|      2020|\n",
      "| 12|  Jennifer|    White|          Biology|      2020|\n",
      "| 13|   Charles|    Black|          Geology|      2020|\n",
      "| 15|     Henry|    Green|      Meteorology|      2020|\n",
      "|  3|     Peter|    Smith|      Engineering|      2021|\n",
      "|  6| Elizabeth|    Brown|              Art|      2021|\n",
      "|  9|   William|    Black|      Mathematics|      2021|\n",
      "| 18|     Emily|    Brown|       Philosophy|      2021|\n",
      "| 20|   Jessica|    White|        Sociology|      2021|\n",
      "| 10|      Mary|    Brown|          Physics|      2022|\n",
      "| 11|    Thomas|    Green|        Chemistry|      2022|\n",
      "| 16|     Nancy|    White|        Economics|      2022|\n",
      "| 17|    Daniel|    Black|Political Science|      2022|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.students\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d281554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deleting records\n",
    "spark.sql(\"delete from iceberg.db.students where class_year < 2020;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d0a80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----------------+----------+\n",
      "| id|first_name|last_name|            major|class_year|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "|  1|      John|      Doe| Computer Science|      2023|\n",
      "|  4|     Susan| Williams|          zoology|      2023|\n",
      "|  5|     David|  Johnson|              Law|      2020|\n",
      "|  8|     Sarah|    White|          English|      2020|\n",
      "| 12|  Jennifer|    White|          Biology|      2020|\n",
      "| 13|   Charles|    Black|          Geology|      2020|\n",
      "| 15|     Henry|    Green|      Meteorology|      2020|\n",
      "|  3|     Peter|    Smith|      Engineering|      2021|\n",
      "|  6| Elizabeth|    Brown|              Art|      2021|\n",
      "|  9|   William|    Black|      Mathematics|      2021|\n",
      "| 18|     Emily|    Brown|       Philosophy|      2021|\n",
      "| 20|   Jessica|    White|        Sociology|      2021|\n",
      "| 10|      Mary|    Brown|          Physics|      2022|\n",
      "| 11|    Thomas|    Green|        Chemistry|      2022|\n",
      "| 16|     Nancy|    White|        Economics|      2022|\n",
      "| 17|    Daniel|    Black|Political Science|      2022|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.students\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e81775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new table used to merge records\n",
    "spark.sql(''' CREATE TABLE iceberg.db.new_table(\n",
    "    id int,\n",
    "    first_name string,\n",
    "    last_name string,\n",
    "    major string,\n",
    "    class_year int\n",
    ") USING iceberg \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6230460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "INSERT INTO iceberg.db.new_table(id, first_name, last_name, major, class_year)\n",
    "VALUES\n",
    "(1, 'James', 'smith', 'Commerce', 2023),\n",
    "(2, 'Jane', 'Foster', 'Astrology', 2018),\n",
    "(20, 'Peter', 'Parker', 'Aerospace', 2019); ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3aeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging records from new_table into students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ff0899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''Merge into iceberg.db.students\n",
    "using (select * from iceberg.db.new_table) nt \n",
    "on iceberg.db.students.id = nt.id\n",
    "when matched then update set \n",
    "iceberg.db.students.id = nt.id,\n",
    "iceberg.db.students.first_name = nt.first_name,\n",
    "iceberg.db.students.last_name = nt.last_name,\n",
    "iceberg.db.students.major = nt.major,\n",
    "iceberg.db.students.class_year = nt.class_year\n",
    "when not matched then insert *;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f406c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----------------+----------+\n",
      "| id|first_name|last_name|            major|class_year|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "|  2|      Jane|   Foster|        Astrology|      2018|\n",
      "|  5|     David|  Johnson|              Law|      2020|\n",
      "|  8|     Sarah|    White|          English|      2020|\n",
      "| 12|  Jennifer|    White|          Biology|      2020|\n",
      "| 13|   Charles|    Black|          Geology|      2020|\n",
      "| 15|     Henry|    Green|      Meteorology|      2020|\n",
      "| 20|     Peter|   Parker|        Aerospace|      2019|\n",
      "| 10|      Mary|    Brown|          Physics|      2022|\n",
      "| 11|    Thomas|    Green|        Chemistry|      2022|\n",
      "| 16|     Nancy|    White|        Economics|      2022|\n",
      "| 17|    Daniel|    Black|Political Science|      2022|\n",
      "|  3|     Peter|    Smith|      Engineering|      2021|\n",
      "|  6| Elizabeth|    Brown|              Art|      2021|\n",
      "|  9|   William|    Black|      Mathematics|      2021|\n",
      "| 18|     Emily|    Brown|       Philosophy|      2021|\n",
      "|  1|     James|    smith|         Commerce|      2023|\n",
      "|  4|     Susan| Williams|          zoology|      2023|\n",
      "+---+----------+---------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.students\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b23b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2023-08-16 19:30:...|8883925395892904687|               null|               true|\n",
      "|2023-08-16 23:38:...|2137995163720816069|8883925395892904687|               true|\n",
      "|2023-08-16 23:51:...|2830019819949322448|2137995163720816069|               true|\n",
      "|2023-08-17 00:47:...|1226269504327663081|2830019819949322448|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#inspecting table history\n",
    "df=spark.sql(\"SELECT * FROM iceberg.db.students.history\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/students/history\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e83f9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|2023-08-16 19:30:...|8883925395892904687|               null|   append|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-16 23:38:...|2137995163720816069|8883925395892904687|overwrite|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-16 23:51:...|2830019819949322448|2137995163720816069|   delete|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-17 00:47:...|1226269504327663081|2830019819949322448|overwrite|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspecting table history\n",
    "df=spark.sql(\"SELECT * FROM iceberg.db.students.snapshots\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/students/snapshots\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7f327",
   "metadata": {},
   "source": [
    "# Merge On Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(''' CREATE TABLE iceberg.db.students2 (\n",
    "    id int,\n",
    "    first_name string,\n",
    "    last_name string,\n",
    "    major string,\n",
    "    class_year int\n",
    ") USING iceberg \n",
    " TBLPROPERTIES (\n",
    "    'write.delete.mode'='merge-on-read',\n",
    "    'write.update.mode'='merge-on-read',\n",
    "    'write.merge.mode'='merge-on-read'\n",
    ")\n",
    "PARTITIONED BY (class_year) ;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "INSERT INTO iceberg.db.students2 (id, first_name, last_name, major, class_year)\n",
    "VALUES\n",
    "(1, 'John', 'Doe', 'Computer Science', 2023),\n",
    "(2, 'Jane', 'Doe', 'Business', 2019),\n",
    "(3, 'Peter', 'Smith', 'Engineering', 2021),\n",
    "(4, 'Susan', 'Williams', 'Nursing', 2023),\n",
    "(5, 'David', 'Johnson', 'Law', 2020),\n",
    "(6, 'Elizabeth', 'Brown', 'Art', 2021),\n",
    "(7, 'Michael', 'Green', 'History', 2019),\n",
    "(8, 'Sarah', 'White', 'English', 2020),\n",
    "(9, 'William', 'Black', 'Mathematics', 2021),\n",
    "(10, 'Mary', 'Brown', 'Physics', 2022),\n",
    "(11, 'Thomas', 'Green', 'Chemistry', 2022),\n",
    "(12, 'Jennifer', 'White', 'Biology', 2020),\n",
    "(13, 'Charles', 'Black', 'Geology', 2020),\n",
    "(14, 'Lisa', 'Brown', 'Astronomy', 2019),\n",
    "(15, 'Henry', 'Green', 'Meteorology', 2020),\n",
    "(16, 'Nancy', 'White', 'Economics', 2022),\n",
    "(17, 'Daniel', 'Black', 'Political Science', 2022),\n",
    "(18, 'Emily', 'Brown', 'Philosophy', 2021),\n",
    "(19, 'Matthew', 'Green', 'Psychology', 2019),\n",
    "(20, 'Jessica', 'White', 'Sociology', 2021); ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a7572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad6b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c6e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
