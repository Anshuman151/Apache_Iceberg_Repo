{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5988767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86d0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "  \t\t#packages\n",
    "        .set('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.4_2.12:1.3.1,software.amazon.awssdk:bundle:2.17.178,software.amazon.awssdk:url-connection-client:2.17.178')\n",
    "  \t\t#SQL Extensions\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\n",
    "  \t\t#Configuring Catalog\n",
    "        .set('spark.sql.catalog.spark_catalog','org.apache.iceberg.spark.SparkSessionCatalog')\n",
    "        .set('spark.sql.catalog.spark_catalog.type','hive')\n",
    "        .set('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.iceberg.type', 'hadoop')\n",
    "        .set('spark.sql.catalog.iceberg.warehouse', 'iceberg-warehouse')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941aa32",
   "metadata": {},
   "source": [
    "spark.appName: The name of the Spark application.\n",
    "spark.jars.packages: A comma-separated list of JARs that should be added to the Spark classpath. These JARs are necessary for using Iceberg with Spark.\n",
    "spark.sql.extensions: The name of the SQL extension that should be used for Iceberg.\n",
    "spark.sql.catalog.iceberg: The name of the catalog that should be used for Iceberg.\n",
    "spark.sql.catalog.iceberg.type: The type of the catalog that should be used for Iceberg.\n",
    "spark.sql.catalog.iceberg.warehouse: The location of the warehouse for the Iceberg catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca01c16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/anshumanr/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/anshumanr/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.4_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5ad9f415-e843-40f4-823b-61a468442c94;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.17.178 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#utils;2.17.178 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.17.178 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.17.178 in central\n",
      ":: resolution report :: resolve 860ms :: artifacts dl 67ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from local-m2-cache in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5ad9f415-e843-40f4-823b-61a468442c94\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 10 already retrieved (0kB/18ms)\n",
      "23/08/10 15:35:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n"
     ]
    }
   ],
   "source": [
    "## Start Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark Running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b66bbb",
   "metadata": {},
   "source": [
    "# Creating a table inside warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd925e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Run a Query to create a table\n",
    "spark.sql(\"CREATE TABLE iceberg.table1 (id integer,name string) USING iceberg;\")\n",
    "\n",
    "## Run a Query to insert into the table\n",
    "spark.sql(\"INSERT INTO iceberg.table1 VALUES (1,'Alex'), (2,'Dipankar'), (3,'Jason')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c097eae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|    Alex|\n",
      "|  2|Dipankar|\n",
      "|  3|   Jason|\n",
      "+---+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Run a Query to get data\n",
    "df = spark.sql(\"SELECT * FROM iceberg.table1\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b054d0",
   "metadata": {},
   "source": [
    "# Creating table inside the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85dff066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE iceberg.db.my_table (name string, age int) USING iceberg;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5a18a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"use iceberg\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b723299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|       db|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f289a6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO iceberg.db.my_table VALUES ('Bob', 20), ('Steve', 36), ('Fiona', 25), ('Roger', 25);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d53b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|  Bob| 20|\n",
      "|Steve| 36|\n",
      "|Fiona| 25|\n",
      "|Roger| 25|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.my_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b710547",
   "metadata": {},
   "source": [
    "# Update records in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f56146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"UPDATE iceberg.db.my_table SET name='Alex' WHERE name='Steve';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb70d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| Alex| 36|\n",
      "|  Bob| 20|\n",
      "|Fiona| 25|\n",
      "|Roger| 25|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.my_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e4bbb",
   "metadata": {},
   "source": [
    "# Changing schema of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bce07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/10 15:37:32 WARN BaseTransaction: Failed to load metadata for a committed snapshot, skipping clean-up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"ALTER TABLE iceberg.db.my_table ADD COLUMNS (email string) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed29cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|email|\n",
      "+-----+---+-----+\n",
      "| Alex| 36| null|\n",
      "|  Bob| 20| null|\n",
      "|Fiona| 25| null|\n",
      "|Roger| 25| null|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.my_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768516f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO iceberg.db.my_table VALUES ('John', 56, 'email@email.email');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8abea723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------+\n",
      "| name|age|            email|\n",
      "+-----+---+-----------------+\n",
      "| John| 56|email@email.email|\n",
      "|  Bob| 20|             null|\n",
      "| Alex| 36|             null|\n",
      "|Fiona| 25|             null|\n",
      "|Roger| 25|             null|\n",
      "+-----+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.my_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "362c4027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"UPDATE iceberg.db.my_table SET email='Alex@gmail.com' WHERE name='Alex';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "626bacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------+\n",
      "| name|age|            email|\n",
      "+-----+---+-----------------+\n",
      "| Alex| 36|   Alex@gmail.com|\n",
      "|  Bob| 20|             null|\n",
      "| John| 56|email@email.email|\n",
      "|Fiona| 25|             null|\n",
      "|Roger| 25|             null|\n",
      "+-----+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from iceberg.db.my_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9022f",
   "metadata": {},
   "source": [
    "# Inspecting our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting table history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "429fb28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2023-08-10 15:36:...|2311303090824495162|               null|               true|\n",
      "|2023-08-10 15:37:...|2559888429599540403|2311303090824495162|               true|\n",
      "|2023-08-10 15:42:...|4939622892415754228|2559888429599540403|               true|\n",
      "|2023-08-10 15:42:...|6500316511377472248|4939622892415754228|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT * FROM iceberg.db.my_table.history\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/my_table/history\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bcc5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cf573ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|2023-08-10 15:36:...|2311303090824495162|               null|   append|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-10 15:37:...|2559888429599540403|2311303090824495162|overwrite|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-10 15:42:...|4939622892415754228|2559888429599540403|   append|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "|2023-08-10 15:42:...|6500316511377472248|4939622892415754228|overwrite|iceberg-warehouse...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"select * from iceberg.db.my_table.snapshots\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/my_table/snapshots\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7881accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpecting file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b8a4850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "|content|           file_path|file_format|spec_id|record_count|file_size_in_bytes|        column_sizes|        value_counts|   null_value_counts|nan_value_counts|        lower_bounds|        upper_bounds|key_metadata|split_offsets|equality_ids|sort_order_id|    readable_metrics|\n",
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "|      0|iceberg-warehouse...|    PARQUET|      0|           1|               976|{1 -> 55, 2 -> 51...|{1 -> 1, 2 -> 1, ...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> Alex, 2 -> ...|{1 -> Alex, 2 -> ...|        null|          [4]|        null|            0|{{51, 1, 0, null,...|\n",
      "|      0|iceberg-warehouse...|    PARQUET|      0|           1|               970|{1 -> 51, 2 -> 47...|{1 -> 1, 2 -> 1, ...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> John, 2 -> ...|{1 -> John, 2 -> ...|        null|          [4]|        null|            0|{{47, 1, 0, null,...|\n",
      "|      0|iceberg-warehouse...|    PARQUET|      0|           1|               636|  {1 -> 50, 2 -> 47}|    {1 -> 1, 2 -> 1}|    {1 -> 0, 2 -> 0}|              {}|{1 -> Bob, 2 -> \u0014...|{1 -> Bob, 2 -> \u0014...|        null|          [4]|        null|            0|{{47, 1, 0, null,...|\n",
      "|      0|iceberg-warehouse...|    PARQUET|      0|           1|               650|  {1 -> 52, 2 -> 47}|    {1 -> 1, 2 -> 1}|    {1 -> 0, 2 -> 0}|              {}|{1 -> Fiona, 2 ->...|{1 -> Fiona, 2 ->...|        null|          [4]|        null|            0|{{47, 1, 0, null,...|\n",
      "|      0|iceberg-warehouse...|    PARQUET|      0|           1|               650|  {1 -> 52, 2 -> 47}|    {1 -> 1, 2 -> 1}|    {1 -> 0, 2 -> 0}|              {}|{1 -> Roger, 2 ->...|{1 -> Roger, 2 ->...|        null|          [4]|        null|            0|{{47, 1, 0, null,...|\n",
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT * FROM iceberg.db.my_table.files\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/my_table/inspect_files\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5b7928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "|content|                path|length|partition_spec_id|  added_snapshot_id|added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries|\n",
      "+-------+--------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "|      0|iceberg-warehouse...|  5852|                0|6500316511377472248|                     1|                        0|                       0|                       0|                          0|                         0|                 []|\n",
      "|      0|iceberg-warehouse...|  5851|                0|4939622892415754228|                     1|                        0|                       0|                       0|                          0|                         0|                 []|\n",
      "|      0|iceberg-warehouse...|  5829|                0|6500316511377472248|                     0|                        0|                       1|                       0|                          0|                         0|                 []|\n",
      "|      0|iceberg-warehouse...|  5855|                0|2559888429599540403|                     0|                        3|                       1|                       0|                          0|                         0|                 []|\n",
      "+-------+--------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT * FROM iceberg.db.my_table.manifests;\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/my_table/manifests\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7859504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------------------+--------------------------+----------------------------+--------------------------+\n",
      "|record_count|file_count|position_delete_record_count|position_delete_file_count|equality_delete_record_count|equality_delete_file_count|\n",
      "+------------+----------+----------------------------+--------------------------+----------------------------+--------------------------+\n",
      "|           5|         5|                           0|                         0|                           0|                         0|\n",
      "+------------+----------+----------------------------+--------------------------+----------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT * FROM iceberg.db.my_table.partitions\")\n",
    "df.show()\n",
    "df.write.save(\"/Users/anshumanr/Documents/Iceberg/Apache_iceberg/iceberg-warehouse/db/my_table/partitions\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9465e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
